# Persistent Read-Side

[[Event Sourcing and CQRS|ES_CQRS]] is a recommended introduction to this section.

[[Persistent Entities|PersistentEntity]] are used for holding the state of individual entities, but they cannot be used for serving queries that span more than one entity. You need to know the identifier of the entity to be able to interact with it. Therefore you need to create another view of the data that is tailored to the queries that the service provides. Lagom has support for populating this read-side view of the data and also for building queries of the read-side.

This separation of the write-side and the read-side of the persistent data is often referred to as the [CQRS](https://msdn.microsoft.com/en-us/library/jj591573.aspx) (Command Query Responibility Segregation) pattern. The [CQRS Journey](https://msdn.microsoft.com/en-us/library/jj554200.aspx) is a great resource for learning more about CQRS.

## Dependency

To use this feature add the following in your project's build:

@[persistence-dependency](code/build-cluster.sbt)

## Query the Read-Side Database

Lagom has support for [Cassandra](http://cassandra.apache.org/) as data store, both for the write-side entities and the read-side queries. It is a very scalable distributed database, and also flexible enough to support most of the use cases that reactive services may have.

Let us first look at how a service implementation can retrieve data from Cassandra.

@[service-impl](code/docs/home/persistence/BlogServiceImpl2.java)

Note that the [CassandraSession](api/index.html?com/lightbend/lagom/javadsl/persistence/cassandra/CassandraSession.html) is injected in the constructor. `CassandraSession` provides several methods in different flavors for executing queries. The one used in the above example returns a `Source`, i.e. a streamed response. There are also methods for retrieving a list of rows, which can be useful when you know that the result set is small, e.g. when you have included a `LIMIT` clause.

All methods in `CassandraSession` are non-blocking and they return a `CompletionStage` or a `Source`. The statements are expressed in [Cassandra Query Language](http://docs.datastax.com/en/cql/3.3/cql/cqlIntro.html) (CQL) syntax. See [Querying tables](http://docs.datastax.com/en/cql/3.3/cql/cql_using/useQueryDataTOC.html) for information about CQL queries.

## Update the Read-Side

We need to transform the events generated by the [[Persistent Entities|PersistentEntity]] into database tables that can be queried as illustrated in the previous section. For that we will use the [CassandraReadSideProcessor](api/index.html?com/lightbend/lagom/javadsl/persistence/cassandra/CassandraReadSideProcessor.html). It will Consume events produced by persistent entities and update one or more tables in Cassandra that are optimized for queries.

This is how a [CassandraReadSideProcessor](api/index.html?com/lightbend/lagom/javadsl/persistence/cassandra/CassandraReadSideProcessor.html) class looks like before filling in the implementation details:

@[processor1](code/docs/home/persistence/BlogEventProcessor1.java)

To make the events available for read-side processing the events must implement the `aggregateTag` method of the [AggregateEvent](api/index.html?com/lightbend/lagom/javadsl/persistence/AggregateEvent.html) interface to define which events belong together. Typically you define this `aggregateTag` on the top level event type of a `PersistentEntity` class.

The [AggregateEventTag](api/index.html?com/lightbend/lagom/javadsl/persistence/AggregateEventTag.html) for the `BlogEvent` is defined as a constant like this:

@[tag](code/docs/home/persistence/BlogEventTag.java)

The `BlogEvent` classes:

@[full-example](code/docs/home/persistence/BlogEvent.java)

In the service implementation you need to inject the [CassandraReadSide](api/index.html?com/lightbend/lagom/javadsl/persistence/cassandra/CassandraReadSide.html) and at startup (in the constructor) register the class that implements the `CassandraReadSideProcessor`. This will make sure that one instance of the processor is always running on one of the nodes in the cluster of the service.

@[register-event-processor](code/docs/home/persistence/BlogServiceImpl3.java)


### aggregateTag

Define the [AggregateEventTag](api/index.html?com/lightbend/lagom/javadsl/persistence/AggregateEventTag.html) in the method `aggregateTag` of the processor. The tag defines which events to process. You should return the same constant value as in the events.

@[tag](code/docs/home/persistence/BlogEventProcessor.java)

### prepare

You must tell where in the event stream the processing should start. This is the primary purpose of the `prepare` method. Each event is associated with a unique offset, a time based UUID. The offset is a parameter to the event handler for each event and it should typically be stored so that it can be retrieved with a `select` statement in the `prepare` method. Use the `CassandraSession` to get the stored offset.

@[select-offset](code/docs/home/persistence/BlogEventProcessor.java)

Return `noOffset()` if you want to processes all events, e.g. when starting the first time or if the number of events are known to be small enough to processes all events.

Typically `prepare` is also used to create prepared statements that are later used when processing the events. Use `CassandraSession.prepare` to create the prepared statements.

@[prepare-statements](code/docs/home/persistence/BlogEventProcessor.java)

Composing those asynchronous `CompletionStage` tasks may look like this:

@[prepare](code/docs/home/persistence/BlogEventProcessor.java)

### defineEventHandlers

The events are processed by event handlers that are defined in the method `defineEventHandlers`. One handler for each event class.

A handler is a `BiFunction` that takes the event and the offset as parameters and returns zero or more bound statements that will be executed before processing next event.

@[event-handlers](code/docs/home/persistence/BlogEventProcessor.java)

In this example we add one row to the `blogsummary` table and update the current offset in the `blogevent_offset` table for each `PostAdded` event. Other event types are ignored.

Note how the prepared statements that were initialized in the `prepare` method are used here.

You can keep state in variables of the enclosing class and update that state safely from the event handlers. The events are processed sequentially, one at a time. An example of such state could be values for calculating a moving average.

If there is a failure when executing the statements the processor will be restarted after a backoff delay. This delay is increased exponentially in case of repeated failures.

## Raw Stream of Events

There is another tool that can be used if you want to do something else with the events than updating tables in Cassandra. You can get a stream of the persistent events with the `eventStream` method of the [PersistentEntityRegistry](api/index.html?com/lightbend/lagom/javadsl/persistence/PersistentEntityRegistry.html).

@[event-stream](code/docs/home/persistence/BlogServiceImpl3.java)

The `eventStream` method takes the event class that implements the `AggregateEventType` and an optional offset, which is the starting point of the stream. It returns a `Source` of `Pair` elements, which contains the event and the associated offset.

This stream will never complete, unless there is failure from retrieving the events from the database. It will continue to deliver new events as they are persisted.

Each such stream of events will continuously generate queries to Cassandra to fetch new events and therefore this tool should be used carefully. Do not run too many such streams. It should typically not be used for service calls invoked by unknown number of clients, but it can be useful for a limited number of background processing jobs.

## Refactoring Consideration

If you use a class name of a event type as the aggregate tag in [AggregateEventTag](api/index.html?com/lightbend/lagom/javadsl/persistence/AggregateEventTag.html) you have to retain the original tag if you change the event class name because this string is part of the stored event data. `AggregateEventTag` has a factory method (and constructor) with a `String tag` parameter for this purpose. Instead of using a class name as tag identifier you can consider to use a string tag up-front. The tag should be unique among the event types of the service.

## Configuration

The default configuration should be good starting point, and the following settings may later be amended to customize the behavior if needed.

@[persistence-read-side](../../../../persistence/src/main/resources/reference.conf)

## Underlying Implementation

The `CassandraSession` is using the [Datastax Java Driver for Apache Cassandra](https://github.com/datastax/java-driver).

Each `CassandraReadSideProcessor` instance is executed by an [Actor](http://doc.akka.io/docs/akka/2.4.4/java/untyped-actors.html) that is managed by [Akka Cluster Singleton](http://doc.akka.io/docs/akka/2.4.4/java/cluster-singleton.html). The processor consumes a stream of persistent events delivered by the `eventsByTag` [Persistence Query](http://doc.akka.io/docs/akka/2.4.4/java/persistence-query.html) implemented by [akka-persistence-cassandra](https://github.com/akka/akka-persistence-cassandra). The tag corresponds to the `tag` defined by the `AggregateEventTag`.

The `eventStream` of the `PersistentEntityRegistry` is also implemented by the `eventsByTag` query.
